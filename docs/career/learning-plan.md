# Continuous Learning Plan

## Weekly Routine

| Time | Activity | Duration |
|------|----------|----------|
| Mon morning | Read 1 AI paper (abstract + key findings) | 30 min |
| Tue evening | Watch 1 technical talk / YouTube video | 45 min |
| Wed evening | Code: build small prototype or contribute to open source | 1.5 hrs |
| Thu morning | Read AI newsletters + blog posts | 30 min |
| Fri evening | Reflect: update learning log, plan next week | 30 min |
| Weekend | Deep dive: follow tutorial, take course module, or write blog post | 2 hrs |

**Total: ~6 hours/week**

---

## Sources

### Papers
- **arXiv daily** — cs.CL, cs.AI sections
- **Papers With Code** — paperswithcode.com (trending + benchmarks)
- **Semantic Scholar** — semanticscholar.org (alerts on topics)
- **Key authors to follow:** Andrej Karpathy, Yann LeCun, Ilya Sutskever, Jason Wei

### Newsletters
- **The Batch** (deeplearning.ai) — Andrew Ng's weekly digest
- **TLDR AI** — tldr.tech/ai — Daily AI news summary
- **AI Engineer Newsletter** — latent.space — Weekly deep technical content
- **Simon Willison's Weblog** — simonwillison.net — Practical AI + LLM insights
- **Ahead of AI** — Sebastian Raschka's magazine

### YouTube Channels
- **Andrej Karpathy** — Neural nets from scratch, GPT explanations
- **3Blue1Brown** — Visual math/ML intuitions
- **Yannic Kilcher** — Paper walkthroughs
- **AI Explained** — Model comparisons, news analysis
- **Fireship** — Quick overviews of AI tools/concepts

### Communities
- **r/LocalLLaMA** — Local model community (Reddit)
- **r/MachineLearning** — Research discussion (Reddit)
- **Latent Space Discord** — AI engineering community
- **Ollama Discord** — Local LLM community
- **LangChain Discord** — Agent/RAG discussion
- **Hugging Face forums** — Model discussions

### Courses (Self-Paced)
- **fast.ai** — Practical Deep Learning (free)
- **DeepLearning.AI** — LLM specializations (Coursera)
- **Hugging Face Course** — NLP with Transformers (free)
- **Stanford CS229** — Machine Learning (YouTube)
- **Stanford CS224N** — NLP with Deep Learning (YouTube)

---

## Skills Roadmap

### Near-Term (1-3 months)
- [ ] Fine-tuning: LoRA/QLoRA on custom datasets
- [ ] Advanced RAG: re-ranking, query expansion, HyDE
- [ ] LLM evaluation: benchmarks, human eval frameworks
- [ ] Streaming architectures: real-time AI pipelines
- [ ] Production observability: LLM tracing, cost tracking

### Mid-Term (3-6 months)
- [ ] Multi-agent systems: crew coordination, delegation patterns
- [ ] Voice AI: Whisper + TTS integration
- [ ] Computer vision basics: CLIP, image understanding
- [ ] MLOps: model versioning, A/B testing, deployment pipelines
- [ ] Vector databases: Pinecone, Qdrant, Weaviate at scale

### Long-Term (6-12 months)
- [ ] Training basics: small model pre-training, RLHF concepts
- [ ] Multimodal AI: text + image + audio reasoning
- [ ] AI safety: alignment, red teaming, constitutional AI
- [ ] Distributed inference: model parallelism, serving at scale
- [ ] Research contribution: publish a blog post / paper on a novel approach

---

## Learning Log Template

### Week of [Date]

**Papers Read:**
- [Paper title] — Key insight: ...

**Videos Watched:**
- [Title] by [Channel] — Takeaway: ...

**Code Written:**
- [What you built/contributed] — Learned: ...

**Blog Posts Read:**
- [Title] — Useful for: ...

**Reflection:**
- What surprised me: ...
- What I want to explore next: ...
- How this connects to my work: ...

---

## Projects to Build Next

| Project | Skills Practiced | Complexity |
|---------|-----------------|------------|
| Fine-tune a model for code review | LoRA, dataset curation, eval | Medium |
| Multi-agent debate system | Agent coordination, protocols | Medium |
| Voice-controlled Lunar | Whisper, TTS, streaming | Medium |
| RAG with re-ranking | Cross-encoders, query expansion | Low-Medium |
| AI code reviewer GitHub Action | CI/CD, LLM integration | Low |
| Image understanding agent | CLIP, multimodal prompts | Medium-High |

---

## Staying Current

The AI field moves fast. Focus on:
1. **Depth over breadth** — Master RAG and agents before chasing every new model
2. **Build > Read** — Prototyping teaches more than papers alone
3. **Community** — Discussions surface insights faster than solo research
4. **Write about it** — Blog posts solidify understanding and build reputation
5. **Revisit fundamentals** — Linear algebra, probability, transformer architecture
