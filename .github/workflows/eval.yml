name: AI Eval Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  # Job 1: Standard checks
  checks:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: pnpm
      - run: pnpm install
      - run: pnpm typecheck

  # Job 2: AI Evaluation
  eval:
    runs-on: ubuntu-latest
    needs: checks  # only run if checks pass
    steps:
      - uses: actions/checkout@v4

      # Node.js setup
      - uses: pnpm/action-setup@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: pnpm

      # Python setup
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      
      # Install Ollama
      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          sleep 5
          ollama pull qwen2.5:3b

      # Install dependencies
      - name: Install Node dependencies
        run: pnpm install

      - name: Install Python dependencies
        run: |
          cd services/eval
          python -m venv .venv
          source .venv/bin/activate
          pip install -r requirements.txt

      # Start services
      - name: Start services
        run: |
          # Start Lunar gateway
          pnpm dev &
          sleep 10
          
          # Start eval service
          cd services/eval
          source .venv/bin/activate
          uvicorn main:app --port 8000 &
          sleep 5

      # Run evaluation
      - name: Run eval suite
        run: |
          cd services/eval
          source .venv/bin/activate
          python runner.py

      # Quality gate
      - name: Check quality gate
        run: |
          cd services/eval
          source .venv/bin/activate
          python gate.py

      # Save report
      - name: Upload eval report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: eval-report
          path: services/eval/reports/

  # Job 3: Regression Detection
  regression-check:
    runs-on: ubuntu-latest
    needs: eval
    steps:
      - uses: actions/checkout@v4

      - name: Download baseline
        uses: actions/download-artifact@v4
        with:
          name: eval-baseline
          path: eval-baseline/
        continue-on-error: true

      - name: Download current results
        uses: actions/download-artifact@v4
        with:
          name: eval-report
          path: eval-results/

      - name: Check for regressions
        run: |
          cd services/eval
          python -c "
          from regression import detect_regressions, print_regression_report, check_regression_gate
          import sys

          try:
              report = detect_regressions(
                  '../../eval-baseline/results.json',
                  '../../eval-results/results.json'
              )
              print_regression_report(report)
              if not check_regression_gate(report):
                  sys.exit(1)
          except FileNotFoundError:
              print('No baseline found. This is the first run.')
          "

      - name: Save as new baseline
        if: github.ref == 'refs/heads/main'
        uses: actions/upload-artifact@v4
        with:
          name: eval-baseline
          path: eval-results/results.json
